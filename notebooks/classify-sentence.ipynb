{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff0f3886-7cf5-46a1-88eb-cf78724b0ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf68e552-a618-4c41-a007-29937374b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)\n",
    "MAX_LEN = 256\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2dfb19ae-299d-4582-a263-4bd91b1a475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary files to use\n",
    "dictionary_file = 'dimension_dictionary.json'\n",
    "dictionary_file_url = \"https://raw.githubusercontent.com/backdem/democracy-datasets/main/dimension_dictionary.json\"\n",
    "\n",
    "if not os.path.exists(dictionary_file):\n",
    "    urllib.request.urlretrieve(dictionary_file_url, dictionary_file)\n",
    "\n",
    "def load_json_dict(dict_file):\n",
    "    with open(dict_file, 'r') as file:\n",
    "        dictionary = json.load(file)\n",
    "        dictionary.append({\n",
    "            'name': 'no_dimension',\n",
    "            'words': []\n",
    "        })\n",
    "        return dictionary\n",
    "\n",
    "dimension_dictionary = load_json_dict(dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5238705-8677-4cfd-8bb9-29d5e1214c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
    "\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(768, 6)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n",
    "        output_2 = self.l2(output_1)\n",
    "        output = self.l3(output_2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a909a265-2abb-4021-baf3-a260250a94b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('BERT_classifier_democracy.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aef75eb7-93b3-45af-9622-78162a4ca002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(sentence, model, max_length=256):\n",
    "    # Encode the sentence\n",
    "    encoding = tokenizer.encode_plus(\n",
    "      sample_text.lower(),\n",
    "      add_special_tokens=True,\n",
    "      max_length=max_length,\n",
    "      padding='max_length',\n",
    "      truncation=True,\n",
    "      return_token_type_ids=True,\n",
    "      return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    def get_dimension_from_prediction(v, dict=dimension_dictionary):\n",
    "        dims = [dim[\"name\"] for dim in dimension_dictionary]    \n",
    "        index = v.index(max(v))    \n",
    "        return dims[index]\n",
    "    \n",
    "    input_ids = encoding[\"input_ids\"]\n",
    "    mask = encoding[\"attention_mask\"]\n",
    "    token_type_ids = encoding[\"token_type_ids\"]\n",
    "    input_ids = input_ids.to(device, dtype=torch.long)\n",
    "    mask = mask.to(device, dtype=torch.long)\n",
    "    token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "    \n",
    "    # Inference\n",
    "    output = model(input_ids, mask, token_type_ids)\n",
    "    return output[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "afecb426-56c0-4038-910b-f44e659155bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statment \"Because of some limited repression against the political opposition and pro-democracy NGOs, the protests of 2011 and 2012 were not repeated in 2016.\" was classified as: participatory.\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Because of some limited repression against the political opposition and pro-democracy NGOs, the protests of 2011 and 2012 were not repeated in 2016.\"\n",
    "predictions = predict_sentence(sample_text, model, MAX_LEN)\n",
    "result_dim = get_dimension_from_prediction(predictions)\n",
    "print(f'Statment \"{sample_text}\" was classified as: {result_dim}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bf5726-43e2-4b4f-a43e-924045efc9db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
