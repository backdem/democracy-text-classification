{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "da8588ef-60db-4f9c-a6de-e9f63d03129a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e868df8d-0e2b-45d9-bf04-e88c8e98cd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(\"Using device: \" + device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "2edcfaa5-02a9-4cc4-b35f-e2ae6e2bc180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found topics: ['electoral', 'participatory', 'media', 'liberal_institution', 'liberal_rights', 'no_dimension']\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Corpus and dictionary files to use\n",
    "corpus_file = 'democracy_reports_corpus.csv'\n",
    "dictionary_file = 'dimension_dictionary.json'\n",
    "corpus_file_url = \"https://github.com/backdem/democracy-datasets/raw/main/democracy_reports_corpus.csv\"\n",
    "dictionary_file_url = \"https://raw.githubusercontent.com/backdem/democracy-datasets/main/dimension_dictionary.json\"\n",
    "\n",
    "# Download datsets if not already downloaded\n",
    "if not os.path.exists(corpus_file):\n",
    "    urllib.request.urlretrieve(corpus_file_url, corpus_file)\n",
    "if not os.path.exists(dictionary_file):\n",
    "    urllib.request.urlretrieve(dictionary_file_url, dictionary_file)\n",
    "\n",
    "def load_json_dict(dict_file):\n",
    "    with open(dict_file, 'r') as file:\n",
    "        dictionary = json.load(file)\n",
    "        dictionary.append({\n",
    "            'name': 'no_dimension',\n",
    "            'words': []\n",
    "        })\n",
    "        return dictionary\n",
    "\n",
    "dimension_dictionary = load_json_dict(dictionary_file)\n",
    "print(f'Found topics: {[dim[\"name\"] for dim in dimension_dictionary]}')\n",
    "# Naive approach to label sentences with dictionary, producing \n",
    "# a masked label vector of the form [0, 0, 0, 0, 0, 1] where the \n",
    "# indicies match topics ['electoral', 'participatory', 'media', 'liberal_institution', 'liberal_rights', 'no_dimension']\n",
    "def generate_label_vector(sentence, dict=dimension_dictionary):\n",
    "    topics = [dim['name'] for dim in dict]\n",
    "    matched_dim = 'no_dimension'\n",
    "    for dim in dict:\n",
    "        if matched_dim != 'no_dimension':\n",
    "            break\n",
    "        for w in dim['words']:\n",
    "            if w in sentence.lower():\n",
    "                matched_dim = dim['name']\n",
    "                break\n",
    "    return [int(t == matched_dim) for t in topics]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "44882512-1124-4aaa-9ee5-06306211f567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 sentence section  country  \\\n",
      "424987  for those reasons, greco is of the firm opinio...    none  hungary   \n",
      "449753  no official study has been made of the extent ...    none   greece   \n",
      "429339  the code was debated upon in three joint sessi...    none   greece   \n",
      "349006  su has a separate budget from the general budg...    none   sweden   \n",
      "311493                            v) privatisation agency    none   latvia   \n",
      "\n",
      "        year source  \n",
      "424987  2008  greco  \n",
      "449753  2001  greco  \n",
      "429339  2017  greco  \n",
      "349006  2018  greco  \n",
      "311493  2002  greco  \n"
     ]
    }
   ],
   "source": [
    "# Read csv file into Dataframe\n",
    "df = pd.read_csv(corpus_file, dtype={'year': str, 'sentence': str}, comment='#')\n",
    "# Print first row\n",
    "print(df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "ba308218-7f5b-4c6c-b0fb-07cf5f305555",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences_labels = pd.DataFrame(df['sentence'])\n",
    "# Insert string label column into DF\n",
    "df_sentences_labels.insert(loc=1,column=\"label_str\", value=df_labels)\n",
    "# Convert string label colum to numerical column\n",
    "#df_sentences_labels['label'] = pd.factorize(df_sentences_labels['label_str'])[0]\n",
    "df_sentences_labels['label'] = df_sentences_labels['label_str'].apply(generate_label_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "b06f297b-13c1-4775-b201-bc4b0d92d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "FRACTION_OF_DS_TO_USE = 0.1\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "d8340b0d-717f-4135-a422-a0d9d8e83059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22470</th>\n",
       "      <td>In practice, each has links to the ruling part...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249126</th>\n",
       "      <td>the functions of judge and prosecutor are inco...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194272</th>\n",
       "      <td>Particularly during the period prior to the 20...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247373</th>\n",
       "      <td>the right to institute the procedure becomes s...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215569</th>\n",
       "      <td>the salaries of ptef are of a public nature an...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257751</th>\n",
       "      <td>finally, the get met with representatives of t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233115</th>\n",
       "      <td>the prosecutor has the right to decide on the ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262432</th>\n",
       "      <td>this concerns in particular, the insufficientl...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235385</th>\n",
       "      <td>(2) if with the crime from item 1 a larger pro...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143376</th>\n",
       "      <td>The next prime minister, Andris Ðíçle 1999 200...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sentence               label\n",
       "22470   In practice, each has links to the ruling part...  [0, 0, 0, 0, 0, 1]\n",
       "249126  the functions of judge and prosecutor are inco...  [0, 0, 0, 0, 0, 1]\n",
       "194272  Particularly during the period prior to the 20...  [0, 0, 0, 1, 0, 0]\n",
       "247373  the right to institute the procedure becomes s...  [0, 0, 0, 0, 0, 1]\n",
       "215569  the salaries of ptef are of a public nature an...  [0, 0, 0, 0, 0, 1]\n",
       "257751  finally, the get met with representatives of t...  [0, 0, 0, 0, 0, 1]\n",
       "233115  the prosecutor has the right to decide on the ...  [0, 0, 0, 0, 0, 1]\n",
       "262432  this concerns in particular, the insufficientl...  [0, 0, 0, 0, 0, 1]\n",
       "235385  (2) if with the crime from item 1 a larger pro...  [0, 0, 0, 0, 0, 1]\n",
       "143376  The next prime minister, Andris Ðíçle 1999 200...  [0, 0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use part of the dataset\n",
    "new_df = df_sentences_labels.sample(frac=FRACTION_OF_DS_TO_USE, random_state=200)\n",
    "# Display a sample of the dataset\n",
    "new_df.sample(10)[['sentence', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "caf982b0-ceba-4f6a-b82a-de77aa727c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.comment_text = dataframe.sentence\n",
    "        self.targets = self.data.label\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comment_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        comment_text = str(self.comment_text[index])\n",
    "        comment_text = \" \".join(comment_text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            comment_text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "aba08395-2d99-4a90-86e2-b9ae7126776c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (46073, 3)\n",
      "TRAIN Dataset: (36858, 3)\n",
      "TEST Dataset: (9215, 3)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "train_dataset=new_df.sample(frac=train_size,random_state=200)\n",
    "test_dataset=new_df.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(new_df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "56ef5fc2-7e42-492f-b784-60af2502b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "63817466-1fa8-4374-98ae-754830ef222d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (l2): Dropout(p=0.3, inplace=False)\n",
       "  (l3): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
    "\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(768, 6)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n",
    "        output_2 = self.l2(output_1)\n",
    "        output = self.l3(output_2)\n",
    "        return output\n",
    "\n",
    "model = BERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "976033ad-b99d-4064-afd8-c8b1735fff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "e4d1e80e-f264-49e5-9246-39c497e48c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "2a6fc239-7a30-447e-8aca-fe460c4ae3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for _,data in enumerate(training_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        if _%5000==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc7deb-ef71-4496-a8ae-49419949da33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.6795785427093506\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92565cc2-618d-4769-baf0-511e9b6f4a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9fb40f-c281-4f5e-813e-b2939c519c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    outputs, targets = validation(epoch)\n",
    "    outputs = np.array(outputs) >= 0.5\n",
    "    accuracy = metrics.accuracy_score(targets, outputs)\n",
    "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
    "    print(f\"Accuracy Score = {accuracy}\")\n",
    "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "    print(f\"F1 Score (Macro) = {f1_score_macro}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
